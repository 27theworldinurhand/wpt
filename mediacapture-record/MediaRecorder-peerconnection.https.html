<!doctype html>
<html>
<meta name="timeout" content="long">

<head>
  <title>MediaRecorder peer connection</title>
  <link rel="help"
        href="https://w3c.github.io/mediacapture-record/MediaRecorder.html#dom-mediarecorder-mimeType">
  <script src="/resources/testharness.js"></script>
  <script src="/resources/testharnessreport.js"></script>
</head>

<body>
  <video id="remote" autoplay width="240" />
  <script>

async function exchangeIceCandidates(pc1, pc2) {
  function doExchange(localPc, remotePc) {
    localPc.addEventListener('icecandidate', event => {
      const { candidate } = event;
      if (candidate && remotePc.signalingState !== 'closed') {
        remotePc.addIceCandidate(candidate);
      }
    });
  }
  doExchange(pc1, pc2);
  doExchange(pc2, pc1);
}

async function exchangeOfferAnswerRaw(pc1, pc2) {
  await pc1.setLocalDescription(await pc1.createOffer());
  await pc2.setRemoteDescription(pc1.localDescription);
  await pc2.setLocalDescription(await pc2.createAnswer());
  await pc1.setRemoteDescription(pc2.localDescription);
}

async function exchangeOfferAnswer(remoteVideo, pc1, pc2, numTracks) {
  const promise = new Promise(resolve => {
    let tracks = [];
    pc2.ontrack = e => {
      tracks.push(e.track)
      if (tracks.length < numTracks) return;
      const stream = new MediaStream(tracks);
      // The srcObject sink is needed for the tests to get exercised in Chrome.
      remoteVideo.srcObject = stream;
      resolve(stream)
    }});
  exchangeOfferAnswerRaw(pc1, pc2);
  return promise;
}

function setTransceiverCodecPreference(transceiver, codecPreference) {
  for (let codec of RTCRtpSender.getCapabilities('video').codecs) {
    if (codec.mimeType.includes(codecPreference)) {
      transceiver.setCodecPreferences([codec]);
      return;
    }
  }
}

async function startConnection(t, useAudio, useVideo, videoCodecPreference) {
  const remoteVideo = document.getElementById('remote');
  const stream = await navigator.mediaDevices.getUserMedia({
    audio: useAudio, video: useVideo
  });
  t.add_cleanup(() => stream.getTracks().forEach(track => track.stop()));
  const pc1 = new RTCPeerConnection();
  t.add_cleanup(() => pc1.close());
  const pc2 = new RTCPeerConnection();
  t.add_cleanup(() => pc2.close());
  let transceivers = {};
  stream.getTracks().forEach(track => {
    const transceiver = pc1.addTransceiver(track);
    transceivers[track.kind] = transceiver;
    if (videoCodecPreference && track.kind == 'video') {
      setTransceiverCodecPreference(transceiver, videoCodecPreference);
    }
  });
  exchangeIceCandidates(pc1, pc2);
  const remoteStream = await exchangeOfferAnswer(
    remoteVideo, pc1, pc2, useAudio + useVideo);
  return [pc1, pc2, remoteStream, transceivers]
}

async function waitForFrames(
    t, pc, lookForAudio, lookForVideo, numFramesOrPackets) {
  const originalTimestampMs = Date.now();
  let initialAudioPackets = 0;
  let initialVideoFrames = 0;
  const timeoutMs = 10000;
  do {
    const report = await pc.getStats();
    report.forEach(stats => {
      if (stats.id) {
        if (lookForAudio && stats.id.includes("RTCInboundRTPAudioStream")) {
          if (!initialAudioPackets) {
            initialAudioPackets = stats.packetsReceived
          } else if (stats.packetsReceived > initialAudioPackets +
                     numFramesOrPackets) {
            lookForAudio = false;
          }
        }
        if (lookForVideo && stats.id.includes("RTCInboundRTPVideoStream")) {
          if (!initialVideoFrames) {
            initialVideoFrames = stats.framesDecoded;
          } else if (stats.framesDecoded > initialVideoFrames +
                     numFramesOrPackets) {
            lookForVideo = false;
          }
        }
      }
    });
    if (lookForAudio || lookForVideo)
      await new Promise(r => { t.step_timeout(r, 100); });
  } while ((lookForAudio || lookForVideo) &&
           Date.now() < originalTimestampMs + timeoutMs);
}

async function waitForCodec(t, pc, codecToLookFor) {
  const originalTimestampMs = Date.now();
  let currentCodecId = 0;
  let done = false;
  const timeoutMs = 10000;
  do {
    const report = await pc.getStats();
    report.forEach(stats => {
      if (stats.id) {
        if (stats.id.includes("RTCInboundRTPVideoStream")) {
          currentCodecId = stats.codecId;
        } else if (stats.id == currentCodecId &&
                   stats.mimeType.toLowerCase().includes(
                      codecToLookFor.toLowerCase())) {
          done = true;
        }
      }
    });
    await new Promise(r => { t.step_timeout(r, 100); });
  } while (!done && Date.now() < originalTimestampMs + timeoutMs);
}


[["video", { video: true, audio: false }, ""],
 ["audio", { video: false, audio: true }, ""],
 ["audio/video", { video: true, audio: true }, ""],
 ["audio", { video: false, audio: true }, "video/webm;codecs=vp8"],
 ["video", { video: true, audio: false }, "video/webm;codecs=vp8"],
 ["audio/video", { video: true, audio: true }, "video/webm;codecs=vp8"],
 ["audio", { video: false, audio: true }, "video/webm;codecs=vp9"],
 ["video", { video: true, audio: false }, "video/webm;codecs=vp9"],
 ["audio/video", { video: true, audio: true }, "video/webm;codecs=vp9"]]
  .forEach(args => {
    const formatString = JSON.stringify(args[1]) +
        " with format " + (args[2] ? args[2] : "[passthrough]") + ".";

    promise_test(async t => {
      const [localPc, remotePc, stream] = await startConnection(
          t, args[1].audio, args[1].video);
      const recorder = new MediaRecorder(stream, { mimeType: args[2] });
      const dataPromise = new Promise(resolve => {
        recorder.onstart = () => {
          recorder.ondataavailable = blob => {
            resolve();
          };
        };
      });
      recorder.start();
      await waitForFrames(t, remotePc, args[1].audio, args[1].video, 10);
      recorder.stop();
      await dataPromise;
      localPc.close();
      remotePc.close();
    }, "PeerConnection MediaRecorder receives data after onstart, " +
          formatString);

    promise_test(async t => {
      const [localPc, remotePc, stream] = await startConnection(
          t, args[1].audio, args[1].video);
      const recorder = new MediaRecorder(stream, { mimeType: args[2] });
      const stopPromise = new Promise(resolve => recorder.onstop = resolve);
      const dataPromise = new Promise(resolve => {
        recorder.ondataavailable = blob => {
          if (blob.data.size) {
            resolve();
          }
        };
      });
      recorder.start();
      await waitForFrames(t, remotePc, args[1].audio, args[1].video, 10);
      remotePc.getTransceivers().forEach(
        transceiver => { transceiver.receiver.track.stop(); });
      // As the tracks ended, we'd like to see data from the recorder.
      // For details:
      // https://www.w3.org/TR/mediastream-recording/#mediarecorder-methods.
      await dataPromise;
      await stopPromise;
      localPc.close();
      remotePc.close();
    }, "PeerConnection MediaRecorder gets ondata on stopping recorded " +
            "tracks " + formatString);
  });

  </script>
</body>

</html>
